{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank\n",
    "from nltk import PCFG\n",
    "from nltk import treetransforms\n",
    "from nltk import induce_pcfg\n",
    "from nltk.parse import pchart\n",
    "\n",
    "train_set = treebank.fileids()[:190]\n",
    "test_set = treebank.fileids()[190:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Créer une grammaire avec les données de trainng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "productions = []\n",
    "probabilities = []\n",
    "for item in train_set:\n",
    "    for tree in treebank.parsed_sents(item):\n",
    "        # perform optional tree transformations, e.g.:\n",
    "        tree.collapse_unary(collapsePOS = False) # Remove branches A-B-C into A-B+C\n",
    "        tree.chomsky_normal_form(horzMarkov = 2) # Remove A->(B,C,D) into A->B,C+D->D\n",
    "        productions += tree.productions()\n",
    "        # probabilities += tree.productions().prob()\n",
    "print(productions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "from collections import Counter\n",
    "\n",
    "pct= 10\n",
    "nb_rules_init = len(productions)\n",
    "nb_rules=int(nb_rules_init* pct/100)\n",
    "\n",
    "nb_rules = 5000\n",
    "productions_largest = list(dict(heapq.nlargest(nb_rules, dict(Counter(productions)).items(), key=lambda x: x[1])))\n",
    "\n",
    "S = Nonterminal('S')\n",
    "grammar = induce_pcfg(S,productions_largest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Mesurer la grammaire créer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.parse import viterbi\n",
    "from nltk.parse import ViterbiParser\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get each left hand side element of the grammar that is associated to a terminal word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_grammar = grammar.productions()\n",
    "non_terminals = []\n",
    "terminal = []\n",
    "\n",
    "for rule in production_grammar:\n",
    "    # if the right hand side is string, that means we need the left hand side\n",
    "    # to add a rule for unknown words\n",
    "    if(isinstance(rule.rhs()[0], str)):\n",
    "        non_terminals.append(rule.lhs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add word for each "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "new_production = productions_largest\n",
    "missing_list = []\n",
    "for item in test_set:\n",
    "    for tree in treebank.parsed_sents(item):\n",
    "        # go through each words\n",
    "        for word in tree.leaves():\n",
    "            # is the word in the grammar\n",
    "            try:\n",
    "                grammar.check_coverage([word])\n",
    "            # if word is not in the grammar\n",
    "            except Exception as missing:\n",
    "                # print(word)\n",
    "                for lhs in non_terminals:\n",
    "                    # append to the grammar\n",
    "                    rhs_new=['UNK']\n",
    "                    new_production.append(nltk.grammar.Production(lhs,rhs_new))\n",
    "                missing_list.append(word)\n",
    "\n",
    "                \n",
    "missing_set = set(missing_list)\n",
    "print(len(missing_set))\n",
    "S = Nonterminal('S')\n",
    "new_grammar = induce_pcfg(S,new_production)\n",
    "# print(new_grammar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create test set with UKN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_words = []\n",
    "for rule in new_grammar.productions():\n",
    "    # if the right hand side is string, that means we need the left hand side\n",
    "    # to add a rule for unknown words\n",
    "    if(isinstance(rule.rhs()[0], str)):\n",
    "        known_words.append(rule.rhs()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_clean = []\n",
    "\n",
    "#C,est bon maintenant\n",
    "\n",
    "for item in test_set:\n",
    "    for tree in treebank.parsed_sents(item):\n",
    "        sentence = []\n",
    "        # print(tree)\n",
    "        for word in tree.leaves():\n",
    "            if word not in known_words:\n",
    "                sentence.append(\"UNK\")\n",
    "            else:\n",
    "                sentence.append(word)\n",
    "        test_set_clean.append(sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viberbi_parser = ViterbiParser(new_grammar)\n",
    "probability_tree = viberbi_parser.parse_all(test_set_clean[0])\n",
    "\n",
    "#pickle.dump(probability_tree, open(\"prob_tree.pkl\", \"wb\" ) )\n",
    "# pickle.load( open( \"prob_tree.pkl\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import Tree\n",
    "\n",
    "viberbi_parser = ViterbiParser(new_grammar)\n",
    "\n",
    "tagger_preds_list = []\n",
    "tagger_test_list = []\n",
    "length_sentence = []\n",
    "time_length_sentence = []\n",
    "\n",
    "# for item in test_set:\n",
    "for item in test_set[:1]:\n",
    "    for tree in treebank.parsed_sents(item):\n",
    "\n",
    "        start =  time.time()\n",
    "\n",
    "        # add the UNK words in the sentence\n",
    "        sentence = []\n",
    "        for word in tree.leaves():\n",
    "            if word not in known_words:\n",
    "                sentence.append(\"UNK\")\n",
    "            else:\n",
    "                sentence.append(word)\n",
    "\n",
    "\n",
    "        test_set_clean.append(sentence)\n",
    "\n",
    "        # Viterbi parser\n",
    "        viberbi_probability_tree = viberbi_parser.parse_all(sentence)\n",
    "        try:\n",
    "            tagger_preds = viberbi_probability_tree[0].pos()\n",
    "            tagger_preds_list.append(tagger_preds)\n",
    "\n",
    "        except:\n",
    "            tagger_preds_list.append([])\n",
    "\n",
    "        tagger_test= tree.pos()\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        # add data to arrays\n",
    "        length_sentence.append(len(sentence))\n",
    "        time_length_sentence.append(end-start)\n",
    "        \n",
    "        tagger_test_list.append(tagger_test)\n",
    "\n",
    "        # save the arrays\n",
    "        pickle.dump(length_sentence, open(\"length_sentence.pkl\", \"wb\" ) )\n",
    "        pickle.dump(time_length_sentence, open(\"time_length_sentence.pkl\", \"wb\" ) )\n",
    "        pickle.dump(tagger_preds_list, open(\"tagger_preds_list.pkl\", \"wb\" ) )\n",
    "        pickle.dump(tagger_test_list, open(\"tagger_test_list.pkl\", \"wb\" ) )\n",
    "\n",
    "        \n",
    "tagger_preds_list = pickle.load( open( \"tagger_preds_list.pkl\", \"rb\" ) )\n",
    "tagger_test_list = pickle.load( open( \"tagger_test_list.pkl\", \"rb\" ) )      \n",
    "\n",
    "# print(tagger_preds_list)\n",
    "# print(tagger_test_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "tests = [tag for sentence in tagger_test_list for _,tag in sentence]\n",
    "preds = [tag for sentence in tagger_preds_list for _,tag in sentence]\n",
    "\n",
    "print(\"Metrics\")\n",
    "print(\" Accuracy :\", metrics.accuracy_score(tests,preds))\n",
    "print(\" Precision:\", metrics.precision_score(tests,preds,average='weighted'))\n",
    "print(\" Recall   :\", metrics.recall_score(tests,preds,average='weighted'))\n",
    "print(\" F1-Score :\", metrics.f1_score(tests,preds,average='weighted'))\n",
    "print()\n",
    "\n",
    "pickle.load( open( \"time_length_sentence.pkl\", \"rb\" ) )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_length_sentence = pickle.load(open( \"length_sentence_5k.pkl\", \"rb\" ))\n",
    "list_time = pickle.load(open( \"time_length_sentence_5k.pkl\", \"rb\" ))\n",
    "tagger_preds = pickle.load(open( \"tagger_preds_list_5k.pkl\", \"rb\" ))\n",
    "tagger_gold = pickle.load(open( \"tagger_test_list_5k.pkl\", \"rb\" ))\n",
    "\n",
    "index = [i for i in range(0,226)]\n",
    "even_nos = [num for num in index if num % 2 == 0] \n",
    "tagger_preds = np.array(tagger_preds)[even_nos]\n",
    "tagger_preds = list(tagger_preds)\n",
    "\n",
    "new_tagger_preds = []\n",
    "new_tagger_gold = []\n",
    "\n",
    "for i,sentence in enumerate(tagger_preds):\n",
    "\n",
    "    if(len(tagger_gold[i]) == len(tagger_preds[i])):\n",
    "        new_tagger_gold.append(tagger_gold[i])\n",
    "        new_tagger_preds.append(tagger_preds[i])\n",
    "\n",
    "tagger_preds = new_tagger_preds\n",
    "tagger_gold = new_tagger_gold\n",
    "\n",
    "list_length_sentence_25 = pickle.load(open( \"result2/length_sentence.pkl\", \"rb\" ))\n",
    "list_time_25 = pickle.load(open( \"result2/time_length_sentence.pkl\", \"rb\" ))\n",
    "tagger_preds_25 = pickle.load(open( \"result2/tagger_preds_list.pkl\", \"rb\" ))\n",
    "tagger_gold_25 = pickle.load(open( \"result2/tagger_test_list.pkl\", \"rb\" ))\n",
    "\n",
    "list_length_sentence_50 = pickle.load(open( \"result3/length_sentence.pkl\", \"rb\" ))\n",
    "list_time_50 = pickle.load(open( \"result3/time_length_sentence.pkl\", \"rb\" ))\n",
    "tagger_preds_50 = pickle.load(open( \"result3/tagger_preds_list.pkl\", \"rb\" ))\n",
    "tagger_gold_50 = pickle.load(open( \"result3/tagger_test_list.pkl\", \"rb\" ))\n",
    "\n",
    "list_length_sentence_100 = pickle.load(open( \"result1/length_sentence.pkl\", \"rb\" ))\n",
    "list_time_100 = pickle.load(open( \"result1/time_length_sentence.pkl\", \"rb\" ))\n",
    "tagger_preds_100 = pickle.load(open( \"result1/tagger_preds_list.pkl\", \"rb\" ))\n",
    "tagger_gold_100 = pickle.load(open( \"result1/tagger_test_list.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = np.argsort(list_length_sentence)\n",
    "list_length_sentence = np.array(list_length_sentence)[order]\n",
    "list_time = np.array(list_time)[order]\n",
    "tagger_preds = np.array(tagger_preds)[order]\n",
    "tagger_gold = np.array(tagger_gold)[order]\n",
    "\n",
    "order = np.argsort(list_length_sentence_50)\n",
    "list_length_sentence_50 = np.array(list_length_sentence_50)[order]\n",
    "list_time_50 = np.array(list_time_50)[order]\n",
    "tagger_preds_50 = np.array(tagger_preds_50)[order]\n",
    "tagger_gold_50 = np.array(tagger_gold_50)[order]\n",
    "\n",
    "order = np.argsort(list_length_sentence_100)\n",
    "list_length_sentence_100 = np.array(list_length_sentence_100)[order]\n",
    "list_time_100 = np.array(list_time_100)[order]\n",
    "tagger_preds_100 = np.array(tagger_preds_100)[order]\n",
    "tagger_gold_100 = np.array(tagger_gold_100)[order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Longuuer phrase et temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list_length_sentence, list_time/60, \"-\", color = '#244864', markersize=3, label = \"2.5% rules\")\n",
    "#plt.plot(list_length_sentence_25, list_time_25/60, \"-\", color = '#34e621', markersize=3, label = \"25% rules\")\n",
    "plt.plot(list_length_sentence_50, list_time_50/60, \"-\", color = '#871f78', markersize=3, label = \"50% rules\")\n",
    "plt.plot(list_length_sentence_100, list_time_100/60, \"-\", color = '#ff0000', markersize=3, label = \"100% rules\")\n",
    "\n",
    "plt.xlabel('Longueur de phrases [mots]', fontsize = 10)\n",
    "plt.ylabel('Temps [min]', fontsize = 10)\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.savefig('time_length.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(lst): \n",
    "    return sum(lst) / len(lst) \n",
    "\n",
    "avg_time = [average(list_time), average(list_time_25), average(list_time_50), average(list_time_100)]\n",
    "nb_rules_initial = [5000, 0.25*, average(list_time_50), average(list_time_100)]\n",
    "\n",
    "plt.plot(list_length_sentence, list_time, \"o\", color = '#244864', markersize=5)\n",
    "\n",
    "plt.xlabel('Longueur de phrases [mots]', fontsize = 10)\n",
    "plt.ylabel('Temps [s]', fontsize = 10)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Longueur phrase et justesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_list = pickle.load( open( \"missing_list.pkl\", \"rb\" ) )\n",
    "def get_accuracy_list(tagger_preds, tagger_gold):\n",
    "\n",
    "    accuracy_each_sentence = []\n",
    "\n",
    "    for i,sentence in enumerate(tagger_preds):\n",
    "\n",
    "        tests = [tag for _,tag in tagger_gold[i]]\n",
    "        preds = [tag for _,tag in tagger_preds[i]]\n",
    "        \n",
    "        acc = metrics.accuracy_score(tests,preds)\n",
    "        accuracy_each_sentence.append(acc)\n",
    "\n",
    "    #print(\" Accuracy :\", metrics.accuracy_score(tests,preds))\n",
    "    #print(\" Precision:\", metrics.precision_score(tests,preds,average='weighted'))\n",
    "    #print(\" Recall   :\", metrics.recall_score(tests,preds,average='weighted'))\n",
    "    #print(\" F1-Score :\", metrics.f1_score(tests,preds,average='weighted'))\n",
    "    return accuracy_each_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(list_length_sentence_50, acc_list_50, \"o\", color = '#871f78', markersize=3, label = \"50% rules\")\n",
    "\n",
    "plt.xlabel('Longueur de phrases [mots]', fontsize = 10)\n",
    "plt.ylabel('Justesse', fontsize = 10)\n",
    "plt.grid()\n",
    "#plt.legend()\n",
    "plt.savefig('acc_length.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proportion de mots inconnus par phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in test_set:\n",
    "count_unk_list = []\n",
    "for item in test_set:\n",
    "    for tree in treebank.parsed_sents(item):\n",
    "        count_unk = 0\n",
    "        start =  time.time()\n",
    "\n",
    "        # add the UNK words in the sentence\n",
    "        sentence = []\n",
    "        for word in tree.leaves():\n",
    "            if word not in known_words:\n",
    "                sentence.append(\"UNK\")\n",
    "                count_unk += 1\n",
    "            else:\n",
    "                sentence.append(word)\n",
    "        count_unk_list.append(count_unk/len(sentence))\n",
    "\n",
    "print(len(count_unk_list))\n",
    "\n",
    "\n",
    "tagger_preds_100 = pickle.load(open( \"result1/tagger_preds_list.pkl\", \"rb\" ))\n",
    "tagger_gold_100 = pickle.load(open( \"result1/tagger_test_list.pkl\", \"rb\" ))\n",
    "\n",
    "order = np.argsort(count_unk_list[:67])\n",
    "list_length_unk_100 = np.array(count_unk_list)[order]\n",
    "tagger_preds_unk_100 = np.array(tagger_preds_100)[order]\n",
    "tagger_gold_unk_100 = np.array(tagger_gold_100)[order]\n",
    "acc_list_100 = get_accuracy_list(tagger_preds_unk_100, tagger_gold_unk_100)\n",
    "\n",
    "plt.plot(list_length_unk_100, acc_list_100, \"o\", color = '#871f78', markersize=3, label = \"100% rules\")\n",
    "\n",
    "plt.xlabel('Proportion de mots inconnus par phrase [mots]', fontsize = 10)\n",
    "plt.ylabel('Justesse', fontsize = 10)\n",
    "plt.grid()\n",
    "plt.savefig('acc_unk_prop.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
