{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kenlm\n",
    "import os\n",
    "import io\n",
    "import nltk\n",
    "import time\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import ToktokTokenizer\n",
    "from string import punctuation\n",
    "import matplotlib.pyplot as plt\n",
    "import tarfile,os\n",
    "import sys\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import xgboost as xgb\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models.word2vec import PathLineSentences\n",
    "import multiprocessing\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from operator import itemgetter \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import FastText\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_accuracy(pred, truth):\n",
    "    good = 0\n",
    "    len_testset = len(truth)\n",
    "\n",
    "    for i in range(len_testset):\n",
    "        if(truth[i] == pred[i]):\n",
    "            good+=1\n",
    "    return good/len_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_pickle(\"clean_trainset.pkl\")\n",
    "test_set = pd.read_pickle(\"clean_testset.pkl\")\n",
    "\n",
    "y_train = train_set[\"sign\"]\n",
    "y_test = test_set[\"sign\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=4000)\n",
    "X_train = tfidf.fit_transform(train_set[\"tokenized_text_string\"].values).toarray()\n",
    "X_test = tfidf.transform(test_set[\"tokenized_text_string\"].values).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06477238007943782\n"
     ]
    }
   ],
   "source": [
    "model = DummyClassifier(strategy='most_frequent')\n",
    "model.fit(X_train, y_train)\n",
    "print(measure_accuracy(model.predict(X_test), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08457073021692636\n"
     ]
    }
   ],
   "source": [
    "gnb = ComplementNB()\n",
    "model_nb = gnb.fit(X_train, y_train)\n",
    "pred_NB = model_nb.predict(X_test)\n",
    "print(measure_accuracy(pred_NB, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08001833180568287"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_clf = xgb.XGBClassifier(n_estimators=100, objective = 'multi:softmax')\n",
    "model_clf = model_clf.fit(X_train, y_train)\n",
    "pred_xgb = model_clf.predict(X_test)\n",
    "measure_accuracy(pred_xgb, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08102658111824014"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm = svm.SVC()\n",
    "model_svm = model_svm.fit(X_train, y_train)\n",
    "preds_svm = model_svm.predict(X_test)\n",
    "measure_accuracy(preds_svm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Euge\\Miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10171096853040025"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp = MLPClassifier(solver='lbfgs', alpha=1e-6, \n",
    "                     hidden_layer_sizes=(6, 5), learning_rate_init=0.001, random_state=1)\n",
    "\n",
    "model_mlp = model_mlp.fit(X_train, y_train)\n",
    "pred_mlp = model_mlp.predict(X_test)\n",
    "measure_accuracy(pred_mlp, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.01      0.05      0.01       264\n",
      "           2       0.20      0.17      0.19      6912\n",
      "           3       0.05      0.07      0.06      1499\n",
      "           4       0.12      0.06      0.08      4461\n",
      "           5       0.17      0.08      0.11      5921\n",
      "           6       0.10      0.08      0.09      3371\n",
      "           7       0.04      0.07      0.06      1298\n",
      "           8       0.00      0.33      0.00         3\n",
      "           9       0.01      0.03      0.02       742\n",
      "          10       0.21      0.11      0.15      7125\n",
      "          11       0.03      0.06      0.04      1134\n",
      "\n",
      "    accuracy                           0.10     32730\n",
      "   macro avg       0.08      0.09      0.07     32730\n",
      "weighted avg       0.15      0.10      0.12     32730\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Euge\\Miniconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(pred_mlp, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07256339749465322"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fc = RandomForestClassifier(max_depth=4, random_state=0)\n",
    "model_fc = model_fc.fit(X_train, y_train)\n",
    "pred_fc = model_fc.predict(X_test)\n",
    "\n",
    "measure_accuracy(pred_fc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr = LinearRegression()\n",
    "model_lr = model_lr.fit(X_train, y_train)\n",
    "pred_lr = model_lr.predict(X_test)\n",
    "\n",
    "measure_accuracy(pred_lr, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08026275588145432"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr = LogisticRegression(multi_class=\"multinomial\", solver=\"newton-cg\")\n",
    "model_lr = model_lr.fit(X_train, y_train)\n",
    "pred_lr = model_lr.predict(X_test)\n",
    "\n",
    "measure_accuracy(pred_lr, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Euge\\Miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08912312862816987"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = LogisticRegression(multi_class='multinomial', random_state=1, max_iter=200)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = ComplementNB()\n",
    "clf4 = model_mlp = MLPClassifier(solver='lbfgs', alpha=1e-6,\n",
    "                     hidden_layer_sizes=(6, 5), random_state=1, max_iter=300)\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "         ('lr', clf1), ('rf', clf2), ('gnb', clf3), ('mlp', clf4)], voting='hard')\n",
    "eclf1 = eclf1.fit(X_train, y_train)\n",
    "pref_eclf = eclf1.predict(X_test)\n",
    "measure_accuracy(pref_eclf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(joblib.load('best_logreg.pkl').best_params_)\n",
    "print(joblib.load('best_forest.pkl').best_params_)\n",
    "print(joblib.load('best_NB.pkl').best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Euge\\Miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213.74872660636902\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.09706691109074243"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "clf1 = LogisticRegression(multi_class='multinomial', tol=0.0001, random_state=1, max_iter=200, C=1.0)\n",
    "clf2 = RandomForestClassifier(n_estimators=100, random_state=1, min_samples_split=4)\n",
    "clf3 = ComplementNB()\n",
    "clf4 = MLPClassifier(solver='lbfgs', alpha=1e-6, learning_rate_init=0.05,\n",
    "                     hidden_layer_sizes=(6, 6, 6, 6), random_state=1, max_iter=100)\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "         ('lr', clf1), ('rf', clf2), ('gnb', clf3), ('mlp', clf4)], voting='hard')\n",
    "eclf1 = eclf1.fit(X_train, y_train)\n",
    "pref_eclf = eclf1.predict(X_test)\n",
    "\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "\n",
    "measure_accuracy(pref_eclf, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Euge\\Miniconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:471: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10171096853040025"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp = MLPClassifier(solver='lbfgs', alpha=1e-6, \n",
    "                     hidden_layer_sizes=(6, 5), learning_rate_init=0.001, random_state=1)\n",
    "\n",
    "model_mlp = model_mlp.fit(X_train, y_train)\n",
    "pred_mlp = model_mlp.predict(X_test)\n",
    "measure_accuracy(pred_mlp, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_average(sent, model):\n",
    "    mean = []\n",
    "    for word in sent:\n",
    "        if word in model.wv.vocab:\n",
    "            mean.append(model.wv.get_vector(word))\n",
    "\n",
    "    if not mean:  # empty words\n",
    "        # If a text is empty, return a vector of zeros.\n",
    "        #logging.warning(\"cannot compute average owing to no vector for {}\".format(sent))\n",
    "        return np.zeros(len_embed)\n",
    "    else:\n",
    "        mean = np.array(mean).mean(axis=0)\n",
    "        return mean\n",
    "\n",
    "\n",
    "def word_average_list(row, model):\n",
    "    average = word_average(row[\"tokenized_text\"], model)\n",
    "    return average\n",
    "\n",
    "#model = Word2Vec.load(\"language_model/w2vmodel.model\")\n",
    "#len_embed = model.vector_size\n",
    "\n",
    "#X_train = train_set.apply(lambda row: word_average_list(row, model), axis=1)\n",
    "#X_test = test_set.apply(lambda row: word_average_list(row, model), axis=1)\n",
    "\n",
    "# X_train.to_pickle(\"X_train_word2vec.pkl\")\n",
    "# X_test.to_pickle(\"X_test_word2vec.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.vstack(pd.read_pickle(\"X_train_word2vec.pkl\"))\n",
    "X_test = np.vstack(pd.read_pickle(\"X_test_word2vec.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06477238007943782"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_mlp = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                     hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "model_mlp = model_mlp.fit(np.vstack(X_train), y_train)\n",
    "pred_mlp = model_mlp.predict(np.vstack(X_test))\n",
    "measure_accuracy(pred_mlp, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0823709135349832"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "model_nb = gnb.fit(np.vstack(X_train), y_train)\n",
    "pred_NB = model_nb.predict(np.vstack(X_test))\n",
    "measure_accuracy(pred_NB, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06431408493736633"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm = svm.SVC()\n",
    "model_svm = model_svm.fit(X_train, y_train)\n",
    "preds_svm = model_svm.predict(X_test)\n",
    "measure_accuracy(preds_svm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08991750687442714"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = LogisticRegression(multi_class='multinomial', random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "eclf1 = VotingClassifier(estimators=[\n",
    "         ('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "eclf1 = eclf1.fit(X_train, y_train)\n",
    "pref_eclf = eclf1.predict(X_test)\n",
    "measure_accuracy(pref_eclf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomSearch for MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 14.0min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 19.6min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 29.6min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 35.2min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 42.3min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 51.2min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 60.2min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 67.3min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 76.6min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 87.6min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 98.7min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 109.6min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 124.2min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 134.3min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 137.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10,\n",
       "                   estimator=Pipeline(steps=[('vect', TfidfVectorizer()),\n",
       "                                             ('model', MLPClassifier())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'model__activation': ['logistic',\n",
       "                                                              'relu', 'lbfgs'],\n",
       "                                        'model__alpha': [0.0001, 1e-05, 1e-06],\n",
       "                                        'model__hidden_layer_sizes': [(6, 5),\n",
       "                                                                      (5, 5),\n",
       "                                                                      (6, 6),\n",
       "                                                                      (7, 5),\n",
       "                                                                      (7, 6),\n",
       "                                                                      (4, 5,\n",
       "                                                                       2)],\n",
       "                                        'model__learning_rate': ['constant',\n",
       "                                                                 'adaptive'],\n",
       "                                        'model__random_state': [1],\n",
       "                                        'model__solver': ['lbfgs', 'adam'],\n",
       "                                        'vect__max_features': [1000, 2000, 3000,\n",
       "                                                               4000]},\n",
       "                   scoring='accuracy', verbose=10)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLPClassifier\n",
    "\n",
    "#model_mlp = MLPClassifier(solver='lbfgs', alpha=1e-6,\n",
    "#                     hidden_layer_sizes=(6, 5), random_state=1)\n",
    "\n",
    "\n",
    "param = {\n",
    "'vect__max_features': [1000, 2000, 3000, 4000],\n",
    "'model__hidden_layer_sizes':  [(6,5), (5,5), (6,6), (7,5), (7,6), (4,5,2)],\n",
    "'model__solver':  ['lbfgs', 'adam'],\n",
    "'model__activation': ['logistic', 'relu', 'lbfgs'],\n",
    "'model__learning_rate': ['constant','adaptive'],\n",
    "'model__random_state': [1],\n",
    "'model__alpha' : [1e-4, 1e-5, 1e-6]\n",
    "}\n",
    "\n",
    "    \n",
    "vectorizer = TfidfVectorizer\n",
    "\n",
    "pipe = Pipeline([\n",
    "        ('vect', vectorizer()),\n",
    "        ('model', model())\n",
    "    ])\n",
    "gs = RandomizedSearchCV(pipe,\n",
    "                      param_distributions=param,  # what parameters values are we searching?\n",
    "                      cv=10,\n",
    "                      n_iter=20,\n",
    "                      scoring='accuracy', verbose=10,\n",
    "                      n_jobs=-1)  # 5-fold cross-validation.\n",
    "\n",
    "\n",
    "# Fit GridSearch to training data.\n",
    "gs.fit(train_set[\"tokenized_text_string\"], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomSearch for VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(multi_class='multinomial', random_state=1, max_iter=200)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "clf3 = ComplementNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Euge\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:282: UserWarning: The total space of parameters 24 is smaller than n_iter=30. Running 24 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  7.5min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 18.4min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 25.6min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 32.0min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 41.0min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 48.4min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 57.4min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 68.9min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 78.2min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 90.4min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 103.1min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 117.8min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 133.6min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 149.2min\n",
      "[Parallel(n_jobs=-1)]: Done 213 tasks      | elapsed: 169.7min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 194.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08023220287198289\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer\n",
    "model = LogisticRegression\n",
    "\n",
    "param = {\n",
    "'vect__max_features': [1000, 4500, 6000],\n",
    "'model__random_state': [1],\n",
    "'model__tol': [1e-4, 1e-5],\n",
    "'model__C': [1.0, 3.0],\n",
    "'model__max_iter' : [200, 300],\n",
    "'model__multi_class' : ['multinomial']\n",
    "}\n",
    "\n",
    "pipe = Pipeline([\n",
    "        ('vect', vectorizer()),\n",
    "        ('model', model())\n",
    "    ])\n",
    "\n",
    "gs = RandomizedSearchCV(pipe,\n",
    "                      param_distributions=param,  # what parameters values are we searching?\n",
    "                      cv=10,\n",
    "                      n_iter=30,\n",
    "                      scoring='accuracy', verbose=10,\n",
    "                      n_jobs=-1)  # 5-fold cross-validation.\n",
    "\n",
    "\n",
    "# Fit GridSearch to training data.\n",
    "gs.fit(train_set[\"tokenized_text_string\"], y_train)\n",
    "\n",
    "joblib.dump(gs, 'best_logreg.pkl')\n",
    "print(accuracy_score(y_test, gs.predict(test_set[\"tokenized_text_string\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Euge\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:282: UserWarning: The total space of parameters 18 is smaller than n_iter=30. Running 18 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed: 12.5min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed: 23.1min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed: 29.9min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed: 45.9min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 61.6min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed: 88.3min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 103.8min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 117.7min\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed: 132.1min\n",
      "[Parallel(n_jobs=-1)]: Done 105 tasks      | elapsed: 158.0min\n",
      "[Parallel(n_jobs=-1)]: Done 120 tasks      | elapsed: 184.5min\n",
      "[Parallel(n_jobs=-1)]: Done 137 tasks      | elapsed: 201.8min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 221.0min\n",
      "[Parallel(n_jobs=-1)]: Done 173 tasks      | elapsed: 255.0min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed: 265.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07381607088298198\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer\n",
    "model = RandomForestClassifier\n",
    "\n",
    "param = {\n",
    "'vect__max_features': [1000, 4500, 6000],\n",
    "'model__random_state':  [1],\n",
    "'model__n_estimators':  [50, 100],\n",
    "'model__min_samples_split': [2,3,4]\n",
    "}\n",
    "\n",
    "pipe = Pipeline([\n",
    "        ('vect', vectorizer()),\n",
    "        ('model', model())\n",
    "    ])\n",
    "\n",
    "gs = RandomizedSearchCV(pipe,\n",
    "                      param_distributions=param,  # what parameters values are we searching?\n",
    "                      cv=10,\n",
    "                      n_iter=30,\n",
    "                      scoring='accuracy', verbose=10,\n",
    "                      n_jobs=-1)  # 5-fold cross-validation.\n",
    "\n",
    "\n",
    "# Fit GridSearch to training data.\n",
    "gs.fit(train_set[\"tokenized_text_string\"], y_train)\n",
    "\n",
    "joblib.dump(gs, 'best_forest.pkl')\n",
    "print(accuracy_score(y_test, gs.predict(test_set[\"tokenized_text_string\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-3757f36780e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# Fit GridSearch to training data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'best_NB.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1060\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1061\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1062\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    938\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer\n",
    "model = ComplementNB\n",
    "\n",
    "\n",
    "param = {\n",
    "'model__alpha': [0.001, 0,1, 0.5, 1],\n",
    "'model__norm': [0, 1]\n",
    "}\n",
    "\n",
    "pipe = Pipeline([\n",
    "        ('model', model())\n",
    "])\n",
    "\n",
    "gs = GridSearchCV(pipe,\n",
    "                      param_grid=param,  # what parameters values are we searching?\n",
    "                      cv=10,\n",
    "                      scoring='accuracy', verbose=10,\n",
    "                      n_jobs=-1)  # 5-fold cross-validation.\n",
    "\n",
    "\n",
    "# Fit GridSearch to training data.\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(gs, 'best_NB.pkl')\n",
    "print(accuracy_score(y_test, gs.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count of distribution for train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1391, 1517, 1625, 1349, 1513, 1530, 1614, 1504, 1467, 1560, 1553,\n",
       "       1696], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.79926673,  6.27253284, 17.90406355,  6.38557898,  7.30522456,\n",
       "        8.26153376,  8.25542316,  6.47723801,  7.57714635,  4.55239841,\n",
       "       11.73235564,  6.47723801])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)[1]/len(y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.59320924, 8.28101971, 8.87057154, 7.36393908, 8.25918445,\n",
       "       8.35198428, 8.81052459, 8.21005513, 8.00807904, 8.51574868,\n",
       "       8.47753698, 9.25814728])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)[1]/len(y_train)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.333333333333334"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.unique(y_test, return_counts=True)[1]/len(y_test)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
