{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALL IMPORT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "import string as st\n",
    "import numpy as np\n",
    "import itertools    \n",
    "from stemming.porter2 import stem\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from joblib import dump\n",
    "\n",
    "stopWords = stopwords.words(\"english\")\n",
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SETTING ALL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TRAINING = \"blog/train/\"\n",
    "PATH_TEST = \"blog/test/test1/\"\n",
    "training_file = os.listdir(PATH_TRAINING)\n",
    "test_file = os.listdir(PATH_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving_by_author(directory,PATH_SOURCE,destinationfile):\n",
    "    data_frame=[]\n",
    "    count=0\n",
    "    for file in directory:\n",
    "        all_text= None\n",
    "        count=count+1\n",
    "        print(count)\n",
    "        path = PATH_SOURCE + file\n",
    "        df = pd.read_csv(path, header=0, sep=',', quotechar='\"', names=['code', 'gender', 'age', 'sign', 'text'])\n",
    "        if df.empty:\n",
    "            print('here')\n",
    "            ff =open(path)\n",
    "            reader = csv.reader(ff)\n",
    "            for row in reader:\n",
    "                df=df.append(pd.DataFrame({ 'code': row[0], 'gender': row[1],'age':row[2],'sign': row[3],'text': row[4]},index=[0]))\n",
    "        all_text = df.groupby('code')['text'].apply(' '.join).reset_index()\n",
    "        text = list(all_text['text'])[0]\n",
    "        df_to_append=pd.DataFrame({ 'code': df['code'][0], 'gender': df['gender'][0],'age':df['age'][0],'sign': df['sign'][0],'text': text},index=[0])\n",
    "        data_frame.append(df_to_append)\n",
    "    new_set = pd.concat(data_frame,ignore_index=True)\n",
    "    new_set.to_csv(destinationfile,index=False)\n",
    "    print(len(new_set))\n",
    "    return new_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_pickle(\"clean_trainset.pkl\")\n",
    "test_set = pd.read_pickle(\"clean_testset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_set=pd.read_pickle(\"blind_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000 entries, 0 to 1999\n",
      "Data columns (total 4 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   code                   2000 non-null   object\n",
      " 1   text                   2000 non-null   object\n",
      " 2   tokenized_text         2000 non-null   object\n",
      " 3   tokenized_text_string  2000 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "quiz_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_train = pd.Series(train_set['tokenized_text']).values\n",
    "tokens_test = pd.Series(test_set['tokenized_text']).values\n",
    "\n",
    "tokens_train_gender = pd.Series(train_set['gender']).values\n",
    "tokens_test_gender = pd.Series(test_set['gender']).values\n",
    "\n",
    "tokens_string_train = pd.Series(train_set['tokenized_text_string']).values\n",
    "tokens_string_test = pd.Series(test_set['tokenized_text_string']).values\n",
    "\n",
    "all_female=pd.Series(train_set[train_set['gender']==1]['tokenized_text']).values\n",
    "all_male=pd.Series(train_set[train_set['gender']==0]['tokenized_text']).values\n",
    "\n",
    "all_result={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GETTING OUR BENCHMARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf= DummyClassifier(strategy='most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(strategy='most_frequent')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(train_set['tokenized_text_string'],train_set['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = clf.predict(test_set['tokenized_text_string'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5060189428658722\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(test_set['gender'],pre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORD2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vect(word, model):\n",
    "    try:\n",
    "        return model.wv[word]\n",
    "    except KeyError:\n",
    "        return np.zeros((model.vector_size,))\n",
    "\n",
    "def mean_vectors(phrase, model):\n",
    "    a=[get_vect(w, model) for w in phrase]\n",
    "    return sum(a)/len(a)\n",
    "\n",
    "def word2vec_features(X, model):\n",
    "    feats = np.vstack([mean_vectors(p, model) for p in X])\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(sg=0,hs=1,negative=0,sorted_vocab=1,workers=cores-1)\n",
    "w2v_model.build_vocab(train_set['tokenized_text'].tolist(), progress_per=10000)\n",
    "w2v_model.train(train_set['tokenized_text'].tolist(), total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "w2v_model.init_sims(replace=True)\n",
    "w2v_model.save('w2vmodel.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec.load(\"w2vmodel.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_train = word2vec_features(tokens_train, model)\n",
    "wv_test = word2vec_features(tokens_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_word2vec = SVC()\n",
    "\n",
    "start_time_train_svm_word2vec= time.time()\n",
    "svm_word2vec.fit(wv_train, tokens_train_gender)\n",
    "end_time_train_svm_word2vec= time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_test_svm_word2vec= time.time()\n",
    "predict_svm_word2vec=svm_word2vec.predict(wv_test)\n",
    "end_time_test_svm_word2vec= time.time()\n",
    "\n",
    "predict_score_svm_word2vec=our_score(predict_svm_word2vec,tokens_test_gender)\n",
    "all_result['svm_word2vec']=[predict_score_svm_word2vec,(end_time_train_svm_word2vec-start_time_train_svm_word2vec),(end_time_test_svm_word2vec-start_time_test_svm_word2vec)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_word2vec = LogisticRegression()\n",
    "\n",
    "start_time_train_lr_word2vec= time.time()\n",
    "lr_word2vec.fit(wv_train, tokens_train_gender)\n",
    "end_time_train_lr_word2vec= time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_test_lr_word2vec= time.time()\n",
    "predict_lr_word2vec=lr_word2vec.predict(wv_test)\n",
    "end_time_test_lr_word2vec= time.time()\n",
    "\n",
    "predict_score_lr_word2vec=our_score(predict_lr_word2vec,tokens_test_gender)\n",
    "all_result['lr_word2vec']=[predict_score_lr_word2vec,(end_time_train_lr_word2vec-start_time_train_lr_word2vec),(end_time_test_lr_word2vec-start_time_test_lr_word2vec)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_word2vec = KMeans(n_clusters=2)\n",
    "start_time_train_svm_word2vec= time.time()\n",
    "km_word2vec.fit(wv_train)\n",
    "end_time_train_svm_word2vec= time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_test_km_word2vec= time.time()\n",
    "predict_km_word2vec=km_word2vec.predict(wv_test)\n",
    "end_time_test_km_word2vec= time.time()\n",
    "\n",
    "predict_score_km_word2vec =our_score(predict_km_word2vec,tokens_test_gender)\n",
    "all_result['km_word']=[predict_score_km_word2vec,(end_time_train_svm_word2vec-start_time_train_svm_word2vec),(end_time_test_km_word2vec-start_time_test_km_word2vec)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_word2vec = MLPClassifier()\n",
    "\n",
    "start_time_train_mlp_word2vec= time.time()\n",
    "mlp_word2vec.fit(wv_train, tokens_train_gender)\n",
    "end_time_train_mlp_word2vec= time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_test_mlp_word2vec= time.time()\n",
    "predict_mlp_word2vec=mlp_word2vec.predict(wv_test)\n",
    "end_time_test_mlp_word2vec= time.time()\n",
    "\n",
    "predict_score_mlp_word2vec=accuracy_score(tokens_test_gender,predict_mlp_word2vec)\n",
    "all_result['mlp_word2vec']=[predict_score_mlp_word2vec,(end_time_train_mlp_word2vec-start_time_train_mlp_word2vec),(end_time_test_mlp_word2vec-start_time_test_mlp_word2vec)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_train = vectorizer.fit_transform(tokens_string_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_test = vectorizer.transform(tokens_string_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_tfidf = SVC()\n",
    "\n",
    "start_time_train_svm_tfidf= time.time()\n",
    "svm_tfidf.fit(tfidf_train, tokens_train_gender)\n",
    "end_time_train_svm_tfidf= time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_test_svm_tfidf= time.time()\n",
    "predict_svm_tfidf=svm_tfidf.predict(tfidf_test)\n",
    "end_time_test_svm_tfidf= time.time()\n",
    "\n",
    "predict_score_svm_tfidf=accuracy_score(tokens_test_gender,predict_svm_tfidf)\n",
    "all_result['svm_tfidf']=[predict_score_svm_tfidf,(end_time_train_svm_tfidf-start_time_train_svm_tfidf),(end_time_test_svm_tfidf-start_time_test_svm_tfidf)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tfidf = LogisticRegression()\n",
    "\n",
    "start_time_train_lr_tfidf= time.time()\n",
    "lr_tfidf.fit(tfidf_train, tokens_train_gender)\n",
    "end_time_train_lr_tfidf= time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_test_lr_tfidf= time.time()\n",
    "predict_lr_tfidf=lr_tfidf.predict(tfidf_test)\n",
    "end_time_test_lr_tfidf= time.time()\n",
    "\n",
    "predict_score_lr_tfidf=accuracy_score(tokens_test_gender,predict_lr_tfidf)\n",
    "all_result['lr_tfidf']=[predict_score_lr_tfidf,(end_time_train_lr_tfidf-start_time_train_lr_tfidf),(end_time_test_lr_tfidf-start_time_test_lr_tfidf)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_tfidf = KMeans(n_clusters=2)\n",
    "start_time_train_km_tfidf= time.time()\n",
    "km_tfidf.fit(tfidf_train)\n",
    "end_time_train_km_tfidf= time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_test_km_tfidf= time.time()\n",
    "predict_km_tfidf=km_tfidf.predict(tfidf_test)\n",
    "end_time_test_km_tfidf= time.time()\n",
    "\n",
    "predict_score_km_tfidf =accuracy_score(tokens_test_gender,predict_km_tfidf)\n",
    "all_result['km_tfidf']=[predict_score_km_tfidf,(end_time_train_km_tfidf-start_time_train_km_tfidf),(end_time_test_km_tfidf-start_time_test_km_tfidf)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_tfidf = MLPClassifier()\n",
    "\n",
    "start_time_train_mlp_tfidf= time.time()\n",
    "mlp_tfidf.fit(tfidf_train, tokens_train_gender)\n",
    "end_time_train_mlp_tfidf= time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_test_mlp_tfidf= time.time()\n",
    "predict_mlp_tfidf=mlp_tfidf.predict(tfidf_test)\n",
    "end_time_test_mlp_tfidf= time.time()\n",
    "\n",
    "predict_score_mlp_tfidf=accuracy_score(tokens_test_gender,predict_mlp_tfidf)\n",
    "all_result['mlp_tfidf']=[predict_score_mlp_tfidf,(end_time_train_mlp_tfidf-start_time_train_mlp_tfidf),(end_time_test_mlp_tfidf-start_time_test_mlp_tfidf)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MALE vs FEMALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_n_first(n,d):\n",
    "    x = itertools.islice(d.items(), 0, n)\n",
    "    for key, value in x:\n",
    "        print(key)\n",
    "        print(value)\n",
    "        print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_list(list_to_merge):\n",
    "    list_to_return=[]\n",
    "    for sublist in list_to_merge:\n",
    "        list_to_return=list_to_return+eval(sublist)\n",
    "    return list_to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male=merge_list(all_male)\n",
    "mal=Counter(male)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female =merge_list(all_female)\n",
    "fem = Counter(female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict_fem={k: v for k, v in sorted(dict(fem).items(), key=lambda item: item[1],reverse=True)}\n",
    "sorted_dict_mal={k: v for k, v in sorted(dict(mal).items(), key=lambda item: item[1],reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_n_first(50,sorted_dict_fem)\n",
    "print_n_first(50,sorted_dict_mal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper-param√®tre & Random search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters= [\n",
    "  {'kernel': ['rbf'],\n",
    "  'gamma': [1,0.1,0.01,0.001,1000,1/len(tokens_string_train)],\n",
    "  'C': [0.1,1,10,100,1000],\n",
    "  'max_iter' : [-1,1000,500,200]},\n",
    "  \n",
    "  {'kernel': ['linear'],\n",
    "   'C': [0.1,1,10,100,1000],\n",
    "  'max_iter' : [-1,1000,500,200]},\n",
    "]\n",
    "\n",
    "metric = 'f1_macro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_svm = RandomizedSearchCV(\n",
    "    SVC(), tuned_parameters, n_iter=12, scoring=metric)\n",
    "grid_search_svm.fit(tfidf_train, tokens_train_gender);\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_search_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_tfidf_best = SVC(max_iter= -1, kernel= 'rbf', gamma= 'scale', C= 100)\n",
    "\n",
    "start_time_train_svm_tfidf_best= time.time()\n",
    "svm_tfidf_best.fit(tfidf_train, tokens_train_gender)\n",
    "end_time_train_svm_tfidf_best= time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_test_svm_tfidf_best= time.time()\n",
    "predict_svm_tfidf_best=svm_tfidf_best.predict(tfidf_test)\n",
    "end_time_test_svm_tfidf_best= time.time()\n",
    "\n",
    "predict_score_svm_tfidf_best=accuracy_score(tokens_test_gender,predict_svm_tfidf_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_result['svm_tfidf_best']=[predict_score_svm_tfidf_best,(end_time_train_svm_tfidf_best-start_time_train_svm_tfidf_best),(end_time_test_svm_tfidf_best-start_time_test_svm_tfidf_best)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_quiz = pd.Series(quiz_set['tokenized_text']).values\n",
    "tokens_string_quiz = pd.Series(quiz_set['tokenized_text_string']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_quiz = vectorizer.transform(tokens_string_quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_svm_tfidf_best=svm_tfidf_best.predict(tfidf_quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_quiz_set=pd.read_pickle(\"blindTest_age.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_quiz_set['gender']=predict_svm_tfidf_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_quiz_set['gender'] = append_quiz_set['gender'].map({1:'female', 0:'male'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_quiz_set=append_quiz_set[['code','gender','age','tokenized_text','tokenized_text_string']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_quiz_set.to_pickle(\"blindTest_age_gender.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_quiz_set.to_csv(\"blindTest_age_gender.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
